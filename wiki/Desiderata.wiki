#summary This page enumerates and explains the design goal for RL-Glue. _BETA_

= Design Goals =

RL-Glue is an interface for connecting reinforcement learning agents, environments, and experiments.

The RL-Glue software project is an implementation of the RL-Glue interface that supports single-agent, discrete-time, lock-step reinforcement learning between agents, environments, and experiments developed by different people, potentially in different languages, which can be run on different physical machines.  

Our design and ongoing improvement to the RL-Glue software project is guided by two principles"

   * Require minimal buy-in
   * Provide maximum flexibility 

== Require Minimal Buy-In ==
The RL-Glue interface should be how you'd want to implement your agents, environments, and experiments.  You should not have to contort your code in uncomfortable ways to implement traditional reinforcement learning.  This is a stronger statement than it might sound:

  * You should be able to use any programming language you want
     * Caveat : you may have to write a [Codec] so that RL-Glue components in other languages know how to talk to your agent.